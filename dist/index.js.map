{"version":3,"file":"index.js","sources":["../src/core/astBuilder.ts","../src/core/tokenizer.ts","../src/core/parser.ts","../src/index.ts"],"sourcesContent":["import type {\r\n  ASTAnyValue,\r\n  ASTArray,\r\n  ASTBoolean,\r\n  ASTChildren,\r\n  ASTNaN,\r\n  ASTNull,\r\n  ASTNumber,\r\n  ASTObject,\r\n  ASTObjectKey,\r\n  ASTResult,\r\n  ASTString,\r\n  ASTUndefined,\r\n} from \"../types/ast\";\r\nimport type TokenizerResult from \"../types/tokenizerResult\";\r\n\r\n/**\r\n * Unraw a string to transform for example \\\\n to \\n\r\n * @param rawString\r\n * @returns\r\n */\r\nfunction unrawString(rawString: string) {\r\n  return rawString.replace(/\\\\(.)/g, function (_, char) {\r\n    if (char === \"n\") return \"\\n\";\r\n    if (char === \"r\") return \"\\r\";\r\n    if (char === \"t\") return \"\\t\";\r\n    if (char === \"b\") return \"\\b\";\r\n    if (char === \"f\") return \"\\f\";\r\n    if (char === \"v\") return \"\\v\";\r\n    return char;\r\n  });\r\n}\r\n\r\nclass ASTBuilder {\r\n  /**\r\n   * Return the error message for a given token\r\n   * @param token\r\n   * @returns\r\n   */\r\n  getErrorMessage(token: TokenizerResult) {\r\n    return `\"${token.value}\" is not valid JSON\\nline: ${token.startLine}, column: ${token.startColumn}`;\r\n  }\r\n\r\n  /**\r\n   * Format a string token to remove useless quotes and parse unicode\r\n   * @param str\r\n   * @returns\r\n   */\r\n  private formatStr(str: string) {\r\n    const content =\r\n      /(`|'|\")/.test(str.charAt(0)) &&\r\n      /(`|'|\")/.test(str.charAt(str.length - 1))\r\n        ? str.substring(1, str.length - 1)\r\n        : str;\r\n    return unrawString(content); // turn \\\\n into \\n ...\r\n  }\r\n\r\n  private appendBoolean(token: TokenizerResult): ASTBoolean {\r\n    return {\r\n      type: \"BOOLEAN\",\r\n      value: token.type === \"TRUE_BOOLEAN\" ? true : false,\r\n    };\r\n  }\r\n\r\n  private appendNullValue(token: TokenizerResult): ASTNull {\r\n    return {\r\n      type: \"NULL_VALUE\",\r\n      value: null,\r\n    };\r\n  }\r\n\r\n  private appendUndefinedValue(token: TokenizerResult): ASTUndefined {\r\n    return {\r\n      type: \"UNDEFINED_VALUE\",\r\n      value: undefined,\r\n    };\r\n  }\r\n\r\n  private appendNaNValue(token: TokenizerResult): ASTNaN {\r\n    return {\r\n      type: \"NAN_VALUE\",\r\n      value: NaN,\r\n    };\r\n  }\r\n\r\n  private appendString(token: TokenizerResult): ASTString {\r\n    return {\r\n      type: \"STRING\",\r\n      value: this.formatStr(token.value),\r\n    };\r\n  }\r\n\r\n  private appendArray(token: TokenizerResult): ASTArray {\r\n    return {\r\n      type: \"ARRAY\",\r\n      properties: [],\r\n    };\r\n  }\r\n\r\n  private appendObject(token: TokenizerResult): ASTObject {\r\n    return {\r\n      type: \"OBJECT\",\r\n      properties: [],\r\n    };\r\n  }\r\n\r\n  private appendNumber(token: TokenizerResult): ASTNumber {\r\n    return {\r\n      type: \"NUMBER\",\r\n      value: Number(token.value),\r\n    };\r\n  }\r\n\r\n  private appendKey(token: TokenizerResult): ASTObjectKey {\r\n    return {\r\n      type: \"OBJECT_KEY\",\r\n      name: this.formatStr(token.value),\r\n      value: null,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Build the AST for given tokens\r\n   * @param tokens\r\n   * @returns\r\n   */\r\n  buildAST(tokens: TokenizerResult[]) {\r\n    const tree: ASTResult = { type: \"JSON\", properties: [] };\r\n    const childrens: ASTChildren[] = [tree];\r\n\r\n    let lastScannedToken: TokenizerResult = null;\r\n    for (let i = 0; i < tokens.length; ++i) {\r\n      const actualToken = tokens[i];\r\n      const actualChild = childrens[childrens.length - 1];\r\n\r\n      const addASTBranch = (branch: ASTAnyValue) => {\r\n        if (\"value\" in actualChild) {\r\n          (actualChild as any).value = branch;\r\n        } else actualChild.properties.push(branch as any);\r\n      };\r\n\r\n      if (\r\n        actualToken.type === \"TRUE_BOOLEAN\" ||\r\n        actualToken.type === \"FALSE_BOOLEAN\"\r\n      ) {\r\n        addASTBranch(this.appendBoolean(actualToken));\r\n      } else if (actualToken.type === \"NULL\") {\r\n        addASTBranch(this.appendNullValue(actualToken));\r\n      } else if (actualToken.type === \"UNDEFINED\") {\r\n        addASTBranch(this.appendUndefinedValue(actualToken));\r\n      } else if (actualToken.type === \"NAN\") {\r\n        addASTBranch(this.appendNaNValue(actualToken));\r\n      } else if (actualToken.type === \"NUMBER\") {\r\n        addASTBranch(this.appendNumber(actualToken));\r\n      } else if (\r\n        actualToken.type === \"STRING\" ||\r\n        actualToken.type === \"UNKNOWN\"\r\n      ) {\r\n        if (actualChild.type === \"OBJECT_KEY\" && actualChild.value !== null)\r\n          childrens.pop();\r\n\r\n        if (actualChild.type === \"OBJECT\") {\r\n          const child = this.appendKey(actualToken);\r\n          addASTBranch(child);\r\n          childrens.push(child);\r\n        } else addASTBranch(this.appendString(actualToken));\r\n      } else if (actualToken.type === \"START_BRACKET\") {\r\n        const child = this.appendArray(actualToken);\r\n        addASTBranch(child);\r\n        childrens.push(child);\r\n      } else if (actualToken.type === \"START_BRACE\") {\r\n        const child = this.appendObject(actualToken);\r\n        addASTBranch(child);\r\n        childrens.push(child);\r\n      } else if (actualToken.type === \"END_BRACKET\" && childrens.length !== 1) {\r\n        childrens.pop();\r\n      } else if (actualToken.type === \"END_BRACE\" && childrens.length !== 1) {\r\n        if (actualChild.type === \"OBJECT_KEY\") childrens.pop();\r\n        childrens.pop();\r\n      } else if (actualToken.type === \"COMA\") {\r\n        if (actualChild.type === \"OBJECT_KEY\") childrens.pop();\r\n      } else if (actualToken.type === \"COLON\") {\r\n        //TODO: Actually we skip useless COLON\r\n      }\r\n\r\n      if (actualToken.type !== \"WHITE_SPACE\") lastScannedToken = actualToken;\r\n    }\r\n\r\n    return tree;\r\n  }\r\n}\r\n\r\nexport default ASTBuilder;\r\n","import type TokenizerResult from \"../types/tokenizerResult\";\r\n\r\ntype Tokens = {\r\n  [key: string]: RegExp;\r\n};\r\n\r\ntype MatcherResult = {\r\n  type: string;\r\n  wordLength: number;\r\n};\r\n\r\ntype Options = {\r\n  tokens?: Tokens;\r\n  defaultType?: string;\r\n  callback?: (token: TokenizerResult) => TokenizerResult;\r\n  concatDefaultType?: boolean;\r\n};\r\n\r\nconst defaultOptions: Options = {\r\n  tokens: {},\r\n  defaultType: \"UNKNOWN\",\r\n  concatDefaultType: true,\r\n  callback: (token) => token,\r\n};\r\n\r\n/**\r\n * Tokenize any string with given tokens\r\n */\r\nclass Tokenizer {\r\n  private options: Options = {};\r\n\r\n  constructor(options: Options = {}) {\r\n    this.options = Object.assign({}, defaultOptions, options);\r\n  }\r\n\r\n  /**\r\n   * Set the default type if no token was match\r\n   * Default: UNKNOWN\r\n   * @param type\r\n   */\r\n  setDefaultType(type: string) {\r\n    this.options.defaultType = type;\r\n  }\r\n\r\n  /**\r\n   * Get the default type if no token was match\r\n   * @returns\r\n   */\r\n  getDefaultType() {\r\n    return this.options.defaultType;\r\n  }\r\n\r\n  /**\r\n   * Get the list registered of the tokens\r\n   * @returns\r\n   */\r\n  getTokens() {\r\n    return this.options.tokens;\r\n  }\r\n\r\n  /**\r\n   * Add a new token to match\r\n   * @param type\r\n   * @param value\r\n   */\r\n  addToken(type: string, value: RegExp) {\r\n    this.options.tokens[type] = value;\r\n  }\r\n\r\n  /**\r\n   * Set the callback function called on each new token\r\n   * @param callback\r\n   */\r\n  setCallback(callback: Options[\"callback\"]) {\r\n    this.options.callback = callback;\r\n  }\r\n\r\n  /**\r\n   * Check if a given token match the start of the string\r\n   * @param str\r\n   * @param type\r\n   * @param value\r\n   * @returns\r\n   */\r\n  private matcher(str: string, type: string, value: RegExp): MatcherResult {\r\n    value.lastIndex = 0;\r\n    const match = value.exec(str);\r\n    if (!match || match.index !== 0) {\r\n      return { type: this.options.defaultType, wordLength: 1 };\r\n    }\r\n    return {\r\n      type,\r\n      wordLength: match[0].length,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Tokenize a string\r\n   * @param str\r\n   * @returns\r\n   */\r\n  tokenize(str: string): TokenizerResult[] {\r\n    const tokens: TokenizerResult[] = [];\r\n    const lines = str.split(/\\n/g);\r\n\r\n    let totalCharDone = 0;\r\n    for (let startLine = 0; startLine < lines.length; ++startLine) {\r\n      const line = lines[startLine];\r\n\r\n      for (let startColumn = 0; startColumn < line.length; ++startColumn) {\r\n        const charIndex = startColumn + totalCharDone;\r\n\r\n        let result = null;\r\n        for (const [type, value] of Object.entries(this.options.tokens)) {\r\n          result = this.matcher(\r\n            str.substring(charIndex, str.length),\r\n            type,\r\n            value\r\n          );\r\n          if (result.type !== this.options.defaultType) break;\r\n        }\r\n\r\n        const matchedSentence = str.substring(\r\n          charIndex,\r\n          charIndex + result.wordLength\r\n        );\r\n        const matchedSentenceLinesNumber =\r\n          matchedSentence.match(/\\n/g)?.length ?? 0;\r\n        const token = this.options.callback({\r\n          type: result.type,\r\n          value: matchedSentence,\r\n          startLine,\r\n          startColumn,\r\n          endLine: startLine + matchedSentenceLinesNumber,\r\n          endColumn: startColumn + result.wordLength - 1, // -1 because we don't want the next char but the last letter of the token value\r\n        });\r\n        if (\r\n          this.options.concatDefaultType &&\r\n          token.type === this.options.defaultType &&\r\n          tokens.length !== 0 &&\r\n          tokens[tokens.length - 1].type === this.options.defaultType\r\n        ) {\r\n          const lastToken = tokens[tokens.length - 1];\r\n          lastToken.value += token.value;\r\n          lastToken.endColumn = token.endColumn;\r\n          lastToken.endLine = token.endLine;\r\n        } else tokens.push(token);\r\n        startColumn += result.wordLength - 1;\r\n      }\r\n\r\n      totalCharDone += line.length + 1; // +1 because the \\n have a length of 1 and is removed by the split\r\n    }\r\n\r\n    return tokens;\r\n  }\r\n}\r\n\r\nexport default Tokenizer;\r\n","import type { ASTArray, ASTObject, ASTResult, ASTSimple } from \"../types/ast\";\r\nimport type {\r\n  JSONArray,\r\n  JSONObject,\r\n  JSONResult,\r\n  JSONPrimitif,\r\n} from \"../types/json\";\r\nimport ASTBuilder from \"./astBuilder\";\r\nimport Tokenizer from \"./tokenizer\";\r\n\r\nconst TOKENS = {\r\n  STRING: /(\"|'|`)(?:\\\\\\1|.|\\n)*?\\1/,\r\n  NUMBER: /(?:\\d+(?:\\.\\d*)?)|(?:\\.\\d+)/,\r\n  WHITE_SPACE: /\\s+/,\r\n  COMA: /,/,\r\n  COLON: /:/,\r\n  TRUE_BOOLEAN: /true/,\r\n  FALSE_BOOLEAN: /false/,\r\n  NULL: /null/,\r\n  UNDEFINED: /undefined/,\r\n  NAN: /NaN/,\r\n  START_BRACKET: /\\[/,\r\n  END_BRACKET: /\\]/,\r\n  START_BRACE: /\\{/,\r\n  END_BRACE: /\\}/,\r\n} as const;\r\n\r\n/**\r\n * JSON parser for a given string\r\n */\r\nclass Parser {\r\n  private tokenizer = new Tokenizer({\r\n    tokens: TOKENS,\r\n  });\r\n  private astBuilder = new ASTBuilder();\r\n\r\n  /**\r\n   * Parse a JSON string and return the object\r\n   * @param str\r\n   * @returns\r\n   */\r\n  parse(str: string | null | boolean | number | undefined): JSONResult {\r\n    str = String(str);\r\n    const tokens = this.tokenizer.tokenize(str);\r\n    const ast = this.astBuilder.buildAST(tokens);\r\n    if (ast.properties.length > 1)\r\n      return ast.properties.map((property) => this.parseASTBranch(property));\r\n    return this.parseASTBranch(ast.properties[0]);\r\n  }\r\n\r\n  private parseASTBranch(\r\n    astBranch: ASTResult[\"properties\"][number]\r\n  ): JSONResult {\r\n    if (astBranch.type === \"OBJECT\") {\r\n      return this.parseObject(astBranch);\r\n    }\r\n\r\n    if (astBranch.type === \"ARRAY\") {\r\n      return this.parseArray(astBranch);\r\n    }\r\n\r\n    return this.parsePrimitif(astBranch);\r\n  }\r\n\r\n  private parseArray(astBranch: ASTArray): JSONArray {\r\n    const json: JSONArray = [];\r\n    for (const property of astBranch.properties) {\r\n      json.push(this.parseASTBranch(property));\r\n    }\r\n    return json;\r\n  }\r\n\r\n  private parseObject(astBranch: ASTObject): JSONObject {\r\n    const json: JSONObject = {};\r\n    for (const property of astBranch.properties) {\r\n      if (property.type !== \"OBJECT_KEY\") continue;\r\n      json[property.name] =\r\n        property.value === null ? null : this.parseASTBranch(property.value);\r\n    }\r\n    return json;\r\n  }\r\n\r\n  private parsePrimitif(astBranch: ASTSimple): JSONPrimitif {\r\n    return astBranch.value;\r\n  }\r\n}\r\n\r\nexport default Parser;\r\n","import Parser from \"./core/parser\";\r\n\r\nconst parser = new Parser();\r\n\r\nexport default parser.parse.bind(parser) as Parser[\"parse\"];\r\n"],"names":["ASTBuilder","getErrorMessage","token","value","startLine","startColumn","formatStr","str","content","test","charAt","length","substring","replace","_","char","appendBoolean","type","appendNullValue","appendUndefinedValue","undefined","appendNaNValue","NaN","appendString","this","appendArray","properties","appendObject","appendNumber","Number","appendKey","name","buildAST","tokens","tree","childrens","i","actualToken","actualChild","addASTBranch","branch","push","pop","child","defaultOptions","defaultType","concatDefaultType","callback","Tokenizer","constructor","options","Object","assign","setDefaultType","getDefaultType","getTokens","addToken","setCallback","matcher","lastIndex","match","exec","index","wordLength","tokenize","lines","split","totalCharDone","line","charIndex","result","entries","matchedSentence","matchedSentenceLinesNumber","_b","_a","endLine","endColumn","lastToken","TOKENS","STRING","NUMBER","WHITE_SPACE","COMA","COLON","TRUE_BOOLEAN","FALSE_BOOLEAN","NULL","UNDEFINED","NAN","START_BRACKET","END_BRACKET","START_BRACE","END_BRACE","parser","tokenizer","astBuilder","parse","String","ast","map","property","parseASTBranch","astBranch","parseObject","parseArray","parsePrimitif","json","bind"],"mappings":"wOAiCA,MAAMA,EAMJC,gBAAgBC,GACd,MAAO,IAAIA,EAAMC,mCAAmCD,EAAME,sBAAsBF,EAAMG,aACvF,CAOOC,UAAUC,GAChB,MAAMC,EACJ,UAAUC,KAAKF,EAAIG,OAAO,KAC1B,UAAUD,KAAKF,EAAIG,OAAOH,EAAII,OAAS,IACnCJ,EAAIK,UAAU,EAAGL,EAAII,OAAS,GAC9BJ,EACN,OAAmBC,EAhCJK,QAAQ,UAAU,SAAUC,EAAGC,GAC9C,MAAa,MAATA,EAAqB,KACZ,MAATA,EAAqB,KACZ,MAATA,EAAqB,KACZ,MAATA,EAAqB,KACZ,MAATA,EAAqB,KACZ,MAATA,EAAqB,KAClBA,CACT,GAyBC,CAEOC,cAAcd,GACpB,MAAO,CACLe,KAAM,UACNd,MAAsB,iBAAfD,EAAMe,KAEhB,CAEOC,gBAAgBhB,GACtB,MAAO,CACLe,KAAM,aACNd,MAAO,KAEV,CAEOgB,qBAAqBjB,GAC3B,MAAO,CACLe,KAAM,kBACNd,WAAOiB,EAEV,CAEOC,eAAenB,GACrB,MAAO,CACLe,KAAM,YACNd,MAAOmB,IAEV,CAEOC,aAAarB,GACnB,MAAO,CACLe,KAAM,SACNd,MAAOqB,KAAKlB,UAAUJ,EAAMC,OAE/B,CAEOsB,YAAYvB,GAClB,MAAO,CACLe,KAAM,QACNS,WAAY,GAEf,CAEOC,aAAazB,GACnB,MAAO,CACLe,KAAM,SACNS,WAAY,GAEf,CAEOE,aAAa1B,GACnB,MAAO,CACLe,KAAM,SACNd,MAAO0B,OAAO3B,EAAMC,OAEvB,CAEO2B,UAAU5B,GAChB,MAAO,CACLe,KAAM,aACNc,KAAMP,KAAKlB,UAAUJ,EAAMC,OAC3BA,MAAO,KAEV,CAOD6B,SAASC,GACP,MAAMC,EAAkB,CAAEjB,KAAM,OAAQS,WAAY,IAC9CS,EAA2B,CAACD,GAGlC,IAAK,IAAIE,EAAI,EAAGA,EAAIH,EAAOtB,SAAUyB,EAAG,CACtC,MAAMC,EAAcJ,EAAOG,GACrBE,EAAcH,EAAUA,EAAUxB,OAAS,GAE3C4B,EAAgBC,IAChB,UAAWF,EACZA,EAAoBnC,MAAQqC,EACxBF,EAAYZ,WAAWe,KAAKD,EAAc,EAGnD,GACuB,iBAArBH,EAAYpB,MACS,kBAArBoB,EAAYpB,KAEZsB,EAAaf,KAAKR,cAAcqB,SAC3B,GAAyB,SAArBA,EAAYpB,KACrBsB,EAAaf,KAAKN,gBAAgBmB,SAC7B,GAAyB,cAArBA,EAAYpB,KACrBsB,EAAaf,KAAKL,qBAAqBkB,SAClC,GAAyB,QAArBA,EAAYpB,KACrBsB,EAAaf,KAAKH,eAAegB,SAC5B,GAAyB,WAArBA,EAAYpB,KACrBsB,EAAaf,KAAKI,aAAaS,SAC1B,GACgB,WAArBA,EAAYpB,MACS,YAArBoB,EAAYpB,KAKZ,GAHyB,eAArBqB,EAAYrB,MAA+C,OAAtBqB,EAAYnC,OACnDgC,EAAUO,MAEa,WAArBJ,EAAYrB,KAAmB,CACjC,MAAM0B,EAAQnB,KAAKM,UAAUO,GAC7BE,EAAaI,GACbR,EAAUM,KAAKE,EAChB,MAAMJ,EAAaf,KAAKD,aAAac,SACjC,GAAyB,kBAArBA,EAAYpB,KAA0B,CAC/C,MAAM0B,EAAQnB,KAAKC,YAAYY,GAC/BE,EAAaI,GACbR,EAAUM,KAAKE,EAChB,MAAM,GAAyB,gBAArBN,EAAYpB,KAAwB,CAC7C,MAAM0B,EAAQnB,KAAKG,aAAaU,GAChCE,EAAaI,GACbR,EAAUM,KAAKE,EAChB,KAA+B,gBAArBN,EAAYpB,MAA+C,IAArBkB,EAAUxB,OACzDwB,EAAUO,MACoB,cAArBL,EAAYpB,MAA6C,IAArBkB,EAAUxB,QAC9B,eAArB2B,EAAYrB,MAAuBkB,EAAUO,MACjDP,EAAUO,OACoB,SAArBL,EAAYpB,KACI,eAArBqB,EAAYrB,MAAuBkB,EAAUO,MACxCL,EAAYpB,KAInBoB,EAAYpB,IACjB,CAED,OAAOiB,CACR,EC3KH,MAAMU,EAA0B,CAC9BX,OAAQ,CAAE,EACVY,YAAa,UACbC,mBAAmB,EACnBC,SAAW7C,GAAUA,GAMvB,MAAM8C,EAGJC,YAAYC,EAAmB,IAFvB1B,KAAO0B,QAAY,GAGzB1B,KAAK0B,QAAUC,OAAOC,OAAO,CAAA,EAAIR,EAAgBM,EAClD,CAODG,eAAepC,GACbO,KAAK0B,QAAQL,YAAc5B,CAC5B,CAMDqC,iBACE,OAAO9B,KAAK0B,QAAQL,WACrB,CAMDU,YACE,OAAO/B,KAAK0B,QAAQjB,MACrB,CAODuB,SAASvC,EAAcd,GACrBqB,KAAK0B,QAAQjB,OAAOhB,GAAQd,CAC7B,CAMDsD,YAAYV,GACVvB,KAAK0B,QAAQH,SAAWA,CACzB,CASOW,QAAQnD,EAAaU,EAAcd,GACzCA,EAAMwD,UAAY,EAClB,MAAMC,EAAQzD,EAAM0D,KAAKtD,GACzB,OAAKqD,GAAyB,IAAhBA,EAAME,MAGb,CACL7C,OACA8C,WAAYH,EAAM,GAAGjD,QAJd,CAAEM,KAAMO,KAAK0B,QAAQL,YAAakB,WAAY,EAMxD,CAODC,SAASzD,WACP,MAAM0B,EAA4B,GAC5BgC,EAAQ1D,EAAI2D,MAAM,OAExB,IAAIC,EAAgB,EACpB,IAAK,IAAI/D,EAAY,EAAGA,EAAY6D,EAAMtD,SAAUP,EAAW,CAC7D,MAAMgE,EAAOH,EAAM7D,GAEnB,IAAK,IAAIC,EAAc,EAAGA,EAAc+D,EAAKzD,SAAUN,EAAa,CAClE,MAAMgE,EAAYhE,EAAc8D,EAEhC,IAAIG,EAAS,KACb,IAAK,MAAOrD,EAAMd,KAAUgD,OAAOoB,QAAQ/C,KAAK0B,QAAQjB,QAMtD,GALAqC,EAAS9C,KAAKkC,QACZnD,EAAIK,UAAUyD,EAAW9D,EAAII,QAC7BM,EACAd,GAEEmE,EAAOrD,OAASO,KAAK0B,QAAQL,YAAa,MAGhD,MAAM2B,EAAkBjE,EAAIK,UAC1ByD,EACAA,EAAYC,EAAOP,YAEfU,EACgC,QAApCC,EAA4B,QAA5BC,EAAAH,EAAgBZ,MAAM,cAAM,IAAAe,OAAA,EAAAA,EAAEhE,cAAM,IAAA+D,EAAAA,EAAI,EACpCxE,EAAQsB,KAAK0B,QAAQH,SAAS,CAClC9B,KAAMqD,EAAOrD,KACbd,MAAOqE,EACPpE,YACAC,cACAuE,QAASxE,EAAYqE,EACrBI,UAAWxE,EAAciE,EAAOP,WAAa,IAE/C,GACEvC,KAAK0B,QAAQJ,mBACb5C,EAAMe,OAASO,KAAK0B,QAAQL,aACV,IAAlBZ,EAAOtB,QACPsB,EAAOA,EAAOtB,OAAS,GAAGM,OAASO,KAAK0B,QAAQL,YAChD,CACA,MAAMiC,EAAY7C,EAAOA,EAAOtB,OAAS,GACzCmE,EAAU3E,OAASD,EAAMC,MACzB2E,EAAUD,UAAY3E,EAAM2E,UAC5BC,EAAUF,QAAU1E,EAAM0E,OAC3B,MAAM3C,EAAOQ,KAAKvC,GACnBG,GAAeiE,EAAOP,WAAa,CACpC,CAEDI,GAAiBC,EAAKzD,OAAS,CAChC,CAED,OAAOsB,CACR,EChJH,MAAM8C,EAAS,CACbC,OAAQ,2BACRC,OAAQ,8BACRC,YAAa,MACbC,KAAM,IACNC,MAAO,IACPC,aAAc,OACdC,cAAe,QACfC,KAAM,OACNC,UAAW,YACXC,IAAK,MACLC,cAAe,KACfC,YAAa,KACbC,YAAa,KACbC,UAAW,MCtBb,MAAMC,EAAS,ID4Bf,MAAA7C,cACUzB,KAASuE,UAAG,IAAI/C,EAAU,CAChCf,OAAQ8C,IAEFvD,KAAAwE,WAAa,IAAIhG,CAmD1B,CA5CCiG,MAAM1F,GACJA,EAAM2F,OAAO3F,GACb,MAAM0B,EAAST,KAAKuE,UAAU/B,SAASzD,GACjC4F,EAAM3E,KAAKwE,WAAWhE,SAASC,GACrC,OAAIkE,EAAIzE,WAAWf,OAAS,EACnBwF,EAAIzE,WAAW0E,KAAKC,GAAa7E,KAAK8E,eAAeD,KACvD7E,KAAK8E,eAAeH,EAAIzE,WAAW,GAC3C,CAEO4E,eACNC,GAEA,MAAuB,WAAnBA,EAAUtF,KACLO,KAAKgF,YAAYD,GAGH,UAAnBA,EAAUtF,KACLO,KAAKiF,WAAWF,GAGlB/E,KAAKkF,cAAcH,EAC3B,CAEOE,WAAWF,GACjB,MAAMI,EAAkB,GACxB,IAAK,MAAMN,KAAYE,EAAU7E,WAC/BiF,EAAKlE,KAAKjB,KAAK8E,eAAeD,IAEhC,OAAOM,CACR,CAEOH,YAAYD,GAClB,MAAMI,EAAmB,CAAA,EACzB,IAAK,MAAMN,KAAYE,EAAU7E,WACT,eAAlB2E,EAASpF,OACb0F,EAAKN,EAAStE,MACO,OAAnBsE,EAASlG,MAAiB,KAAOqB,KAAK8E,eAAeD,EAASlG,QAElE,OAAOwG,CACR,CAEOD,cAAcH,GACpB,OAAOA,EAAUpG,KAClB,UChFY2F,EAAOG,MAAMW,KAAKd"}